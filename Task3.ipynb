{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc08e69d-c0c9-41d5-b1a5-a4ab0d479592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiran\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiran\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\kiran/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [02:14<00:00, 348kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 93241155584.0000\n",
      "Epoch 2, Loss: 94191285484.3077\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Multimodal Housing Price Prediction (Self-Contained)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Generate Fake Housing Dataset\n",
    "# -----------------------------\n",
    "os.makedirs(\"dummy_houses\", exist_ok=True)\n",
    "\n",
    "num_samples = 200\n",
    "# Tabular data\n",
    "tabular_data = pd.DataFrame({\n",
    "    \"rooms\": np.random.randint(1, 6, num_samples),\n",
    "    \"area\": np.random.randint(500, 3500, num_samples),\n",
    "    \"location_score\": np.random.uniform(0, 1, num_samples),\n",
    "    \"price\": np.random.randint(50_000, 500_000, num_samples)  # target variable\n",
    "})\n",
    "\n",
    "# Save dummy images\n",
    "for i in range(num_samples):\n",
    "    img = Image.fromarray(np.uint8(np.random.rand(128, 128, 3) * 255))  # noisy RGB image\n",
    "    img.save(f\"dummy_houses/house_{i}.jpg\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Dataset Class\n",
    "# -----------------------------\n",
    "class HousingDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tabular_features = self.df.iloc[idx][[\"rooms\", \"area\", \"location_score\"]].values.astype(np.float32)\n",
    "        target = np.float32(self.df.iloc[idx][\"price\"])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, f\"house_{idx}.jpg\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(tabular_features), torch.tensor(target)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: DataLoader\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = HousingDataset(tabular_data, \"dummy_houses\", transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Multimodal Model\n",
    "# -----------------------------\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, tabular_input_dim):\n",
    "        super(MultiModalNet, self).__init__()\n",
    "        # CNN backbone (ResNet18 pretrained)\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()  # keep features (512-dim)\n",
    "\n",
    "        # Tabular branch\n",
    "        self.fc_tab = nn.Sequential(\n",
    "            nn.Linear(tabular_input_dim, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Final regression\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tabular):\n",
    "        img_feat = self.cnn(img)               # (batch, 512)\n",
    "        tab_feat = self.fc_tab(tabular)        # (batch, 64)\n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        return self.fc_final(combined).squeeze()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Train Model\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiModalNet(tabular_input_dim=3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train 2 epochs (demo)\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, tabs, targets in dataloader:\n",
    "        imgs, tabs, targets = imgs.to(device), tabs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, tabs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc1923d-84bb-4e62-83a3-e86eebda3ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 279.3307\n",
      "Epoch 2, Loss: 271.8826\n",
      "Epoch 3, Loss: 265.0653\n",
      "Epoch 4, Loss: 253.2413\n",
      "Epoch 5, Loss: 241.0056\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(\"dummy_houses\", exist_ok=True)\n",
    "\n",
    "num_samples = 200\n",
    "tabular_data = pd.DataFrame({\n",
    "    \"rooms\": np.random.randint(1, 6, num_samples),\n",
    "    \"area\": np.random.randint(500, 3500, num_samples),\n",
    "    \"location_score\": np.random.uniform(0, 1, num_samples),\n",
    "    \"price\": np.random.randint(50_000, 500_000, num_samples)  # target variable\n",
    "})\n",
    "\n",
    "# Normalize target to thousands\n",
    "tabular_data[\"price\"] = tabular_data[\"price\"] / 1000.0\n",
    "\n",
    "# Scale tabular features\n",
    "scaler = StandardScaler()\n",
    "tabular_data[[\"rooms\", \"area\", \"location_score\"]] = scaler.fit_transform(\n",
    "    tabular_data[[\"rooms\", \"area\", \"location_score\"]]\n",
    ")\n",
    "\n",
    "# Save dummy images (random noise)\n",
    "for i in range(num_samples):\n",
    "    img = Image.fromarray(np.uint8(np.random.rand(128, 128, 3) * 255))\n",
    "    img.save(f\"dummy_houses/house_{i}.jpg\")\n",
    "\n",
    "class HousingDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tabular_features = self.df.iloc[idx][[\"rooms\", \"area\", \"location_score\"]].values.astype(np.float32)\n",
    "        target = np.float32(self.df.iloc[idx][\"price\"])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, f\"house_{idx}.jpg\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(tabular_features), torch.tensor(target)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = HousingDataset(tabular_data, \"dummy_houses\", transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, tabular_input_dim):\n",
    "        super(MultiModalNet, self).__init__()\n",
    "        # CNN backbone (ResNet18 pretrained)\n",
    "        self.cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.cnn.fc = nn.Identity()  # keep features (512-dim)\n",
    "\n",
    "        # Tabular branch\n",
    "        self.fc_tab = nn.Sequential(\n",
    "            nn.Linear(tabular_input_dim, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Final regression\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tabular):\n",
    "        img_feat = self.cnn(img)               # (batch, 512)\n",
    "        tab_feat = self.fc_tab(tabular)        # (batch, 64)\n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        return self.fc_final(combined).squeeze()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiModalNet(tabular_input_dim=3).to(device)\n",
    "criterion = nn.L1Loss()   # MAE instead of MSE\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train for 5 epochs (demo)\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, tabs, targets in dataloader:\n",
    "        imgs, tabs, targets = imgs.to(device), tabs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, tabs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4d5e2-5a26-45ca-9826-79c4742ac50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
